import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# å°‚é–€å®¶ã®ç¨®é¡ã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å®šç¾©
EXPERT_TYPES = {
    "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒˆ": "ã‚ãªãŸã¯å„ªç§€ãªãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒˆã§ã™ã€‚æœè£…ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆã€ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ³ãƒ‰ã«ã¤ã„ã¦å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚",
    "æ „é¤Šå£«": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªæ „é¤Šå£«ã§ã™ã€‚å¥åº·çš„ãªé£Ÿäº‹ã€æ „é¤Šãƒãƒ©ãƒ³ã‚¹ã€é£Ÿç”Ÿæ´»ã®æ”¹å–„ã«ã¤ã„ã¦å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚",
    "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã§ã™ã€‚é‹å‹•æ–¹æ³•ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒ³ã€ä½“åŠ›å‘ä¸Šã«ã¤ã„ã¦å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚",
    "å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼": "ã‚ãªãŸã¯å„ªç§€ãªå¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã€ã‚¹ãƒˆãƒ¬ã‚¹ç®¡ç†ã€äººé–“é–¢ä¿‚ã«ã¤ã„ã¦å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚"
}


def get_llm_response(user_input: str, expert_type: str) -> str:
    """
    LLMã‹ã‚‰å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    
    Args:
        user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        expert_type (str): é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®ç¨®é¡
    
    Returns:
        str: LLMã‹ã‚‰ã®å›ç­”
    """
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å–å¾—
    system_message = EXPERT_TYPES.get(expert_type, "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
    
    # ChatOpenAIãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.7)
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    messages = [
        SystemMessage(content=system_message),
        HumanMessage(content=user_input),
    ]
    
    # LLMã«å•ã„åˆã‚ã›
    result = llm.invoke(messages)
    
    return result.content


def main():
    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(
        page_title="AIå°‚é–€å®¶ç›¸è«‡ã‚¢ãƒ—ãƒª",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ¤– AIå°‚é–€å®¶ç›¸è«‡ã‚¢ãƒ—ãƒª")
    
    # ã‚¢ãƒ—ãƒªã®èª¬æ˜
    st.markdown("""
    ### ğŸ“– ã‚¢ãƒ—ãƒªã®æ¦‚è¦
    ã“ã®ã‚¢ãƒ—ãƒªã¯ã€æ§˜ã€…ãªåˆ†é‡ã®å°‚é–€å®¶AIã«ç›¸è«‡ã§ãã‚‹ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã§ã™ã€‚
    LangChainã¨OpenAIã®GPT-4o-miniãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
    
    ### ğŸ¯ ä½¿ã„æ–¹
    1. **å°‚é–€å®¶ã‚’é¸æŠ**: ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„
    2. **è³ªå•ã‚’å…¥åŠ›**: ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«ç›¸è«‡ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„
    3. **é€ä¿¡**: ã€Œå›ç­”ã‚’å–å¾—ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€AIã‹ã‚‰ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    
    ---
    """)
    
    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("âš™ï¸ è¨­å®š")
        
        # å°‚é–€å®¶ã®ç¨®é¡ã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸æŠ
        expert_type = st.radio(
            "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„:",
            options=list(EXPERT_TYPES.keys()),
            help="é¸æŠã—ãŸå°‚é–€å®¶ã®è¦–ç‚¹ã‹ã‚‰å›ç­”ãŒæä¾›ã•ã‚Œã¾ã™"
        )
        
        # é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®èª¬æ˜ã‚’è¡¨ç¤º
        st.info(f"**é¸æŠä¸­**: {expert_type}")
    
    with col2:
        st.subheader("ğŸ’¬ è³ªå•å…¥åŠ›")
        
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        user_input = st.text_area(
            "ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
            height=150,
            placeholder=f"{expert_type}ã«ç›¸è«‡ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
            help="è³ªå•ã‚„ç›¸è«‡ã—ãŸã„å†…å®¹ã‚’è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        # é€ä¿¡ãƒœã‚¿ãƒ³
        if st.button("ğŸš€ å›ç­”ã‚’å–å¾—", type="primary", use_container_width=True):
            if user_input.strip():
                # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤º
                with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    try:
                        # LLMã‹ã‚‰å›ç­”ã‚’å–å¾—
                        response = get_llm_response(user_input, expert_type)
                        
                        # å›ç­”ã‚’è¡¨ç¤º
                        st.success("âœ… å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ!")
                        st.subheader("ğŸ“ AIã‹ã‚‰ã®å›ç­”")
                        st.markdown(f"**{expert_type}ã¨ã—ã¦ã®å›ç­”:**")
                        st.write(response)
                        
                    except Exception as e:
                        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                        st.info("ğŸ’¡ OPENAI_API_KEYãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.warning("âš ï¸ ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray;'>
        <small>Powered by LangChain & OpenAI GPT-4o-mini</small>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
